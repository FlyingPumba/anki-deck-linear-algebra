{
  "id": "14",
  "title": "Lesson 14: Eigenvectors and Eigenvalues",
  "lesson_title": "Eigenvectors and eigenvalues",
  "objectives": [
    "Understand eigenvectors and eigenvalues",
    "Find eigenvalues using the characteristic polynomial",
    "Work with eigenbases",
    "Diagonalize matrices"
  ],
  "cards": [
    {
      "uid": "linear-algebra-14-001",
      "front": "What is an eigenvector?",
      "back": "A non-zero vector that stays on its own span (line through origin) when transformed.<br><br>It only gets stretched, squished, or flipped - never rotated off its line.",
      "tags": [
        "ch14",
        "eigenvector",
        "definition"
      ]
    },
    {
      "uid": "linear-algebra-14-002",
      "front": "What is an eigenvalue?",
      "back": "The scalar factor \\( \\lambda \\) by which an eigenvector is stretched or squished during the transformation.<br><br>If \\( \\vec{v} \\) is an eigenvector: \\( A\\vec{v} = \\lambda\\vec{v} \\)",
      "tags": [
        "ch14",
        "eigenvalue",
        "definition"
      ]
    },
    {
      "uid": "linear-algebra-14-003",
      "front": "What is the defining equation for eigenvectors and eigenvalues?",
      "back": "\\( A\\vec{v} = \\lambda\\vec{v} \\)<br><br>The matrix \\( A \\) acting on eigenvector \\( \\vec{v} \\) gives the same result as simply scaling \\( \\vec{v} \\) by \\( \\lambda \\).",
      "tags": [
        "ch14",
        "eigen",
        "equation"
      ]
    },
    {
      "uid": "linear-algebra-14-004",
      "front": "How do you find eigenvalues?",
      "back": "Solve: \\( \\det(A - \\lambda I) = 0 \\)<br><br>This is called the characteristic equation. Its solutions are the eigenvalues.",
      "tags": [
        "ch14",
        "eigenvalue",
        "computation"
      ]
    },
    {
      "uid": "linear-algebra-14-005",
      "front": "What do different eigenvalue values mean geometrically?",
      "back": "<ul><li>\\( \\lambda > 1 \\): eigenvector stretched</li><li>\\( 0 < \\lambda < 1 \\): eigenvector squished</li><li>\\( \\lambda < 0 \\): eigenvector flipped and scaled</li><li>\\( \\lambda = 1 \\): eigenvector unchanged</li><li>\\( \\lambda = 0 \\): eigenvector squished to origin</li></ul>",
      "tags": [
        "ch14",
        "eigenvalue",
        "geometry"
      ]
    },
    {
      "uid": "linear-algebra-14-006",
      "front": "For a 3D rotation, what is special about the eigenvalue 1?",
      "back": "The eigenvector with eigenvalue 1 is the axis of rotation.<br><br>It's the only direction that doesn't move during the rotation.",
      "tags": [
        "ch14",
        "eigen",
        "rotation"
      ]
    },
    {
      "uid": "linear-algebra-14-007",
      "front": "What is an eigenbasis?",
      "back": "A basis consisting entirely of eigenvectors.<br><br>In this basis, the transformation matrix becomes diagonal, with eigenvalues on the diagonal. This greatly simplifies calculations like matrix powers.",
      "tags": [
        "ch14",
        "eigenbasis",
        "definition"
      ]
    },
    {
      "uid": "linear-algebra-14-008",
      "front": "Can every matrix be diagonalized (have an eigenbasis)?",
      "back": "No. A matrix can be diagonalized only if it has enough linearly independent eigenvectors to form a basis.<br><br>Some matrices (like shears) don't have enough eigenvectors.",
      "tags": [
        "ch14",
        "diagonalization",
        "conditions"
      ]
    },
    {
      "uid": "linear-algebra-14-009",
      "front": "What is the diagonalization formula for a matrix \\( A \\)?",
      "back": "\\( A = PDP^{-1} \\)<br><br>Where:<br><br><ul><li>\\( P \\) is the matrix whose columns are eigenvectors of \\( A \\)</li><li>\\( D \\) is the diagonal matrix with eigenvalues on the diagonal</li></ul>",
      "tags": [
        "ch14",
        "diagonalization",
        "formula"
      ]
    },
    {
      "uid": "linear-algebra-14-010",
      "front": "How do you find eigenvectors once you know an eigenvalue \\( \\lambda \\)?",
      "back": "Solve \\( (A - \\lambda I)\\vec{v} = \\vec{0} \\)<br><br>Find the null space of \\( (A - \\lambda I) \\). Any non-zero vector in this null space is an eigenvector for \\( \\lambda \\).",
      "tags": [
        "ch14",
        "eigenvector",
        "computation"
      ]
    },
    {
      "uid": "linear-algebra-14-011",
      "front": "Why is diagonalization useful for computing matrix powers?",
      "back": "If \\( A = PDP^{-1} \\), then:<br><br>\\( A^n = PD^nP^{-1} \\)<br><br>Raising a diagonal matrix to a power is trivial: just raise each diagonal entry to that power.",
      "tags": [
        "ch14",
        "diagonalization",
        "application"
      ]
    },
    {
      "uid": "linear-algebra-14-012",
      "front": "What is the eigenspace of an eigenvalue?",
      "back": "The set of all eigenvectors corresponding to that eigenvalue, plus the zero vector.<br><br>It is the null space of \\( (A - \\lambda I) \\) and forms a subspace.",
      "tags": [
        "ch14",
        "eigenspace",
        "definition"
      ]
    },
    {
      "uid": "linear-algebra-14-013",
      "front": "What is algebraic multiplicity vs geometric multiplicity of an eigenvalue?",
      "back": "<b>Algebraic multiplicity</b>: how many times \\( \\lambda \\) appears as a root of the characteristic polynomial.<br><br><b>Geometric multiplicity</b>: the dimension of the eigenspace (number of linearly independent eigenvectors).<br><br>Geometric \\( \\leq \\) Algebraic. A matrix is diagonalizable iff they are equal for all eigenvalues.",
      "tags": [
        "ch14",
        "multiplicity",
        "diagonalization"
      ]
    }
  ]
}
